{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# TICKET-10 Golden Path E2E Validation\n",
        "\n",
        "This notebook validates the full Docker integration path for TICKET-10.\n",
        "\n",
        "## What this covers\n",
        "- Ghostfolio + agent health checks\n",
        "- Seeded-data precondition verification\n",
        "- Five scripted `/api/agent/chat` queries over SSE\n",
        "- Event-order and tool-routing assertions\n",
        "- Follow-up continuity check using a shared `thread_id`\n",
        "\n",
        "## Prerequisites\n",
        "- Stack running with:\n",
        "  - `docker compose -f docker/docker-compose.yml -f docker/docker-compose.agent.yml --env-file .env up -d --build`\n",
        "- `.env` contains a valid `GHOSTFOLIO_ACCESS_TOKEN`\n",
        "- Seed data already imported (`docker/seed-data.json`)"
      ],
      "id": "5d9ec194"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from __future__ import annotations\n",
        "\n",
        "import json\n",
        "from pathlib import Path\n",
        "from typing import Any\n",
        "from urllib import error, request\n",
        "\n",
        "GHOSTFOLIO_URL = \"http://localhost:3333\"\n",
        "AGENT_URL = \"http://localhost:8000\"\n",
        "EXPECTED_MIN_ACTIVITY_COUNT = 26\n",
        "SSE_TIMEOUT_SECONDS = 180\n",
        "\n",
        "\n",
        "def find_repo_root(start: Path | None = None) -> Path:\n",
        "    current = (start or Path.cwd()).resolve()\n",
        "    for candidate in [current, *current.parents]:\n",
        "        if (candidate / \".env\").exists() and (candidate / \"docker\").exists():\n",
        "            return candidate\n",
        "    raise FileNotFoundError(\"Could not locate repository root with .env and docker/ directory\")\n",
        "\n",
        "\n",
        "def read_env(path: Path) -> dict[str, str]:\n",
        "    env: dict[str, str] = {}\n",
        "    for raw_line in path.read_text().splitlines():\n",
        "        line = raw_line.strip()\n",
        "        if not line or line.startswith(\"#\") or \"=\" not in line:\n",
        "            continue\n",
        "        key, value = line.split(\"=\", 1)\n",
        "        env[key.strip()] = value.strip().strip('\"')\n",
        "    return env\n",
        "\n",
        "\n",
        "REPO_ROOT = find_repo_root()\n",
        "ENV_PATH = REPO_ROOT / \".env\"\n",
        "SEED_PATH = REPO_ROOT / \"docker\" / \"seed-data.json\"\n",
        "ENV = read_env(ENV_PATH)\n",
        "\n",
        "print(f\"Repo root: {REPO_ROOT}\")\n",
        "print(f\"Seed file exists: {SEED_PATH.exists()}\")\n",
        "print(f\"Access token present in .env: {bool(ENV.get('GHOSTFOLIO_ACCESS_TOKEN'))}\")"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "eef2d279"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "def http_json(\n",
        "    method: str,\n",
        "    url: str,\n",
        "    payload: dict[str, Any] | None = None,\n",
        "    headers: dict[str, str] | None = None,\n",
        "    timeout: int = 30,\n",
        ") -> tuple[int, dict[str, Any]]:\n",
        "    body: bytes | None = None\n",
        "    request_headers = {\"Content-Type\": \"application/json\"}\n",
        "    if headers:\n",
        "        request_headers.update(headers)\n",
        "\n",
        "    if payload is not None:\n",
        "        body = json.dumps(payload).encode(\"utf-8\")\n",
        "\n",
        "    req = request.Request(url, data=body, headers=request_headers, method=method)\n",
        "\n",
        "    try:\n",
        "        with request.urlopen(req, timeout=timeout) as resp:\n",
        "            raw = resp.read().decode(\"utf-8\")\n",
        "            return resp.status, json.loads(raw) if raw else {}\n",
        "    except error.HTTPError as exc:\n",
        "        raw = exc.read().decode(\"utf-8\")\n",
        "        try:\n",
        "            parsed = json.loads(raw) if raw else {}\n",
        "        except Exception:\n",
        "            parsed = {\"raw\": raw}\n",
        "        return exc.code, parsed\n",
        "\n",
        "\n",
        "def get_bearer_token(access_token: str) -> str:\n",
        "    status, payload = http_json(\n",
        "        \"POST\",\n",
        "        f\"{GHOSTFOLIO_URL}/api/v1/auth/anonymous\",\n",
        "        payload={\"accessToken\": access_token},\n",
        "    )\n",
        "    assert status == 201, f\"Auth exchange failed (status={status}, payload={payload})\"\n",
        "\n",
        "    auth_token = payload.get(\"authToken\")\n",
        "    assert isinstance(auth_token, str) and auth_token, \"Auth token missing from auth response\"\n",
        "    return auth_token\n",
        "\n",
        "\n",
        "def parse_sse_block(block: str) -> dict[str, Any] | None:\n",
        "    if not block.strip():\n",
        "        return None\n",
        "\n",
        "    event_type: str | None = None\n",
        "    payload: dict[str, Any] = {}\n",
        "    for line in block.splitlines():\n",
        "        if line.startswith(\"event:\"):\n",
        "            event_type = line.split(\":\", 1)[1].strip()\n",
        "        elif line.startswith(\"data:\"):\n",
        "            try:\n",
        "                payload = json.loads(line.split(\":\", 1)[1].strip())\n",
        "            except Exception:\n",
        "                payload = {}\n",
        "\n",
        "    if event_type is None:\n",
        "        return None\n",
        "\n",
        "    return {\"event\": event_type, \"data\": payload}\n",
        "\n",
        "\n",
        "def stream_chat(message: str, thread_id: str | None = None, timeout: int = SSE_TIMEOUT_SECONDS) -> dict[str, Any]:\n",
        "    request_payload: dict[str, Any] = {\"message\": message}\n",
        "    if thread_id:\n",
        "        request_payload[\"thread_id\"] = thread_id\n",
        "\n",
        "    req = request.Request(\n",
        "        f\"{AGENT_URL}/api/agent/chat\",\n",
        "        data=json.dumps(request_payload).encode(\"utf-8\"),\n",
        "        headers={\"Content-Type\": \"application/json\", \"Accept\": \"text/event-stream\"},\n",
        "        method=\"POST\",\n",
        "    )\n",
        "\n",
        "    events: list[dict[str, Any]] = []\n",
        "    status_code = 0\n",
        "\n",
        "    with request.urlopen(req, timeout=timeout) as resp:\n",
        "        status_code = resp.status\n",
        "        buffer = \"\"\n",
        "        while True:\n",
        "            chunk = resp.read(2048)\n",
        "            if not chunk:\n",
        "                break\n",
        "\n",
        "            buffer += chunk.decode(\"utf-8\", errors=\"ignore\")\n",
        "            while \"\\n\\n\" in buffer:\n",
        "                block, buffer = buffer.split(\"\\n\\n\", 1)\n",
        "                parsed = parse_sse_block(block)\n",
        "                if parsed:\n",
        "                    events.append(parsed)\n",
        "                    if parsed[\"event\"] in {\"done\", \"error\"}:\n",
        "                        break\n",
        "\n",
        "            if events and events[-1][\"event\"] in {\"done\", \"error\"}:\n",
        "                break\n",
        "\n",
        "    event_types = [item[\"event\"] for item in events]\n",
        "    terminal_event = event_types[-1] if event_types else None\n",
        "    tool_calls = [item for item in events if item[\"event\"] == \"tool_call\"]\n",
        "\n",
        "    done_payload = events[-1][\"data\"] if terminal_event == \"done\" else {}\n",
        "    error_payload = events[-1][\"data\"] if terminal_event == \"error\" else {}\n",
        "\n",
        "    response = done_payload.get(\"response\", {}) if isinstance(done_payload, dict) else {}\n",
        "    response_message = response.get(\"message\", \"\") if isinstance(response, dict) else \"\"\n",
        "\n",
        "    return {\n",
        "        \"status_code\": status_code,\n",
        "        \"message\": message,\n",
        "        \"thread_id\": done_payload.get(\"thread_id\") if isinstance(done_payload, dict) else thread_id,\n",
        "        \"event_types\": event_types,\n",
        "        \"terminal_event\": terminal_event,\n",
        "        \"tool_calls\": tool_calls,\n",
        "        \"done_payload\": done_payload,\n",
        "        \"error_payload\": error_payload,\n",
        "        \"response_message\": response_message,\n",
        "        \"events\": events,\n",
        "    }"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "9a1fbf3a"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "access_token = ENV.get(\"GHOSTFOLIO_ACCESS_TOKEN\", \"\")\n",
        "assert access_token, \"GHOSTFOLIO_ACCESS_TOKEN is missing from .env\"\n",
        "\n",
        "status_gf, payload_gf = http_json(\"GET\", f\"{GHOSTFOLIO_URL}/api/v1/health\")\n",
        "status_agent, payload_agent = http_json(\"GET\", f\"{AGENT_URL}/health\")\n",
        "assert status_gf == 200, f\"Ghostfolio health failed: {status_gf}, {payload_gf}\"\n",
        "assert status_agent == 200, f\"Agent health failed: {status_agent}, {payload_agent}\"\n",
        "\n",
        "bearer_token = get_bearer_token(access_token)\n",
        "\n",
        "orders_status, orders_payload = http_json(\n",
        "    \"GET\",\n",
        "    f\"{GHOSTFOLIO_URL}/api/v1/order?range=max\",\n",
        "    headers={\"Authorization\": f\"Bearer {bearer_token}\"},\n",
        ")\n",
        "details_status, details_payload = http_json(\n",
        "    \"GET\",\n",
        "    f\"{GHOSTFOLIO_URL}/api/v1/portfolio/details\",\n",
        "    headers={\"Authorization\": f\"Bearer {bearer_token}\"},\n",
        ")\n",
        "\n",
        "activities = orders_payload.get(\"activities\", []) if isinstance(orders_payload, dict) else []\n",
        "holdings = details_payload.get(\"holdings\", {}) if isinstance(details_payload, dict) else {}\n",
        "\n",
        "assert orders_status == 200, f\"Orders fetch failed: {orders_status}, {orders_payload}\"\n",
        "assert details_status == 200, f\"Portfolio details fetch failed: {details_status}, {details_payload}\"\n",
        "assert isinstance(activities, list), \"Orders payload is not a list\"\n",
        "assert isinstance(holdings, dict), \"Holdings payload is not a dictionary\"\n",
        "assert len(activities) >= EXPECTED_MIN_ACTIVITY_COUNT, (\n",
        "    f\"Expected at least {EXPECTED_MIN_ACTIVITY_COUNT} activities, got {len(activities)}\"\n",
        ")\n",
        "assert len(holdings) > 0, \"Seed precondition failed: holdings are empty\"\n",
        "\n",
        "print(\n",
        "    {\n",
        "        \"ghostfolio_health\": payload_gf,\n",
        "        \"agent_health\": payload_agent,\n",
        "        \"orders_count\": len(activities),\n",
        "        \"details_holdings_count\": len(holdings),\n",
        "    }\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "34efa43f"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "GOLDEN_PATH_QUERIES = [\n",
        "    \"How is my portfolio doing ytd?\",\n",
        "    \"Categorize my transactions for max range.\",\n",
        "    \"Estimate my tax liability for 2025 in middle bracket.\",\n",
        "    \"Am I diversified enough for a balanced profile?\",\n",
        "    \"Based on that, where am I most concentrated?\",\n",
        "]\n",
        "\n",
        "EXPECTED_PRIMARY_TOOLS = {\n",
        "    1: \"analyze_portfolio_performance\",\n",
        "    2: \"categorize_transactions\",\n",
        "    3: \"estimate_capital_gains_tax\",\n",
        "    4: \"advise_asset_allocation\",\n",
        "    5: \"advise_asset_allocation\",\n",
        "}\n",
        "\n",
        "\n",
        "def assert_query_success(result: dict[str, Any], expected_tool: str, label: str) -> None:\n",
        "    assert result[\"status_code\"] == 200, f\"{label}: HTTP status was {result['status_code']}\"\n",
        "    assert result[\"event_types\"], f\"{label}: no SSE events received\"\n",
        "    assert result[\"event_types\"][0] == \"thinking\", f\"{label}: first event was not thinking\"\n",
        "    assert result[\"terminal_event\"] == \"done\", (\n",
        "        f\"{label}: expected terminal done event, got {result['terminal_event']}\"\n",
        "    )\n",
        "\n",
        "    assert \"tool_call\" in result[\"event_types\"], f\"{label}: tool_call event missing\"\n",
        "    assert \"tool_result\" in result[\"event_types\"], f\"{label}: tool_result event missing\"\n",
        "\n",
        "    first_tool_call = result[\"tool_calls\"][0][\"data\"] if result[\"tool_calls\"] else {}\n",
        "    observed_tool = first_tool_call.get(\"tool\")\n",
        "    assert observed_tool == expected_tool, (\n",
        "        f\"{label}: expected tool {expected_tool}, got {observed_tool}\"\n",
        "    )\n",
        "\n",
        "    assert isinstance(result[\"response_message\"], str) and result[\"response_message\"].strip(), (\n",
        "        f\"{label}: empty final response message\"\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "1c417cc5"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "results: dict[int, dict[str, Any]] = {}\n",
        "\n",
        "# Queries 1-3 run as independent prompts.\n",
        "for index in range(1, 4):\n",
        "    prompt = GOLDEN_PATH_QUERIES[index - 1]\n",
        "    result = stream_chat(prompt)\n",
        "    assert_query_success(result, EXPECTED_PRIMARY_TOOLS[index], f\"Q{index}\")\n",
        "    results[index] = result\n",
        "\n",
        "# Query 4 starts a thread that Query 5 follows.\n",
        "q4_result = stream_chat(GOLDEN_PATH_QUERIES[3])\n",
        "assert_query_success(q4_result, EXPECTED_PRIMARY_TOOLS[4], \"Q4\")\n",
        "\n",
        "follow_up_thread_id = q4_result.get(\"thread_id\")\n",
        "assert isinstance(follow_up_thread_id, str) and follow_up_thread_id, (\n",
        "    \"Q4 did not return a thread_id for continuity check\"\n",
        ")\n",
        "\n",
        "q5_result = stream_chat(GOLDEN_PATH_QUERIES[4], thread_id=follow_up_thread_id)\n",
        "assert_query_success(q5_result, EXPECTED_PRIMARY_TOOLS[5], \"Q5\")\n",
        "assert q5_result.get(\"thread_id\") == follow_up_thread_id, (\n",
        "    \"Q5 thread_id does not match Q4 thread_id\"\n",
        ")\n",
        "\n",
        "results[4] = q4_result\n",
        "results[5] = q5_result\n",
        "\n",
        "print({\n",
        "    \"query_count\": len(results),\n",
        "    \"follow_up_thread_id\": follow_up_thread_id,\n",
        "    \"q5_thread_id\": q5_result.get(\"thread_id\"),\n",
        "    \"q5_terminal_event\": q5_result.get(\"terminal_event\"),\n",
        "})"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "db7f6746"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "snapshots: list[dict[str, Any]] = []\n",
        "for index in range(1, 6):\n",
        "    result = results[index]\n",
        "    first_tool_call = result[\"tool_calls\"][0][\"data\"] if result[\"tool_calls\"] else {}\n",
        "    snapshots.append(\n",
        "        {\n",
        "            \"query\": GOLDEN_PATH_QUERIES[index - 1],\n",
        "            \"tool\": first_tool_call.get(\"tool\"),\n",
        "            \"event_types\": result[\"event_types\"],\n",
        "            \"thread_id\": result.get(\"thread_id\"),\n",
        "            \"response_preview\": result.get(\"response_message\", \"\")[:220],\n",
        "        }\n",
        "    )\n",
        "\n",
        "snapshots"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "eba960ac"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Notes\n",
        "\n",
        "- If precondition checks fail, re-run seed import before running Q1-Q5.\n",
        "- The follow-up continuity check in this notebook verifies same-thread routing via `thread_id` between Q4 and Q5.\n",
        "- Keep snapshot output from the final cell for regression comparison before demos."
      ],
      "id": "9994a1a0"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}